{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94420"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/midhun/Github/Modules/')\n",
    "\n",
    "from alpha import iterate_minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 model\n",
    "class Model:\n",
    "    def __init__(self, data_X, data_y):\n",
    "        self.n_class = 10\n",
    "        self._create_architecture(data_X, data_y)\n",
    "\n",
    "    def _create_architecture(self, data_X, data_y):\n",
    "        y_hot = tf.one_hot(data_y, depth = self.n_class)\n",
    "        logits = self._create_model(data_X)\n",
    "        predictions = tf.argmax(logits, 1, output_type = tf.int32)\n",
    "        self.loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = y_hot, \n",
    "                                                                              logits = logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(self.loss)\n",
    "        self.accuracy = tf.reduce_sum(tf.cast(tf.equal(predictions, data_y), tf.float32))\n",
    "\n",
    "    def _create_model(self, X):\n",
    "        X1 = X - 0.5\n",
    "        X1 = tf.pad(X1, tf.constant([[0, 0], [2, 2], [2, 2], [0, 0]]))\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected], \n",
    "                            weights_initializer = tf.truncated_normal_initializer(0.0, 0.1)):\n",
    "            net = slim.conv2d(X1, 6, [5, 5], padding = 'VALID')\n",
    "            net = slim.max_pool2d(net, [2, 2])\n",
    "            net = slim.conv2d(net, 16, [5, 5], padding = 'VALID')\n",
    "            net = slim.max_pool2d(net, [2, 2])\n",
    "            \n",
    "            net = tf.reshape(net, [-1, 400])\n",
    "            net = slim.fully_connected(net, 120)\n",
    "            net = slim.fully_connected(net, 84)\n",
    "            net = slim.fully_connected(net, self.n_class, activation_fn = None)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val     = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test   = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550016it [00:26, 20826.90it/s]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average training accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "iterations = len(y_train) * epochs\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "# Generate the complete Dataset required in the pipeline\n",
    "dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "data_X, data_y = iterator.get_next()\n",
    "data_y = tf.cast(data_y, tf.int32)\n",
    "model = Model(data_X, data_y)\n",
    "\n",
    "with tf.Session() as sess, tqdm(total = iterations) as pbar:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    tot_accuracy = 0\n",
    "    try:\n",
    "        while True:\n",
    "            accuracy, _ = sess.run([model.accuracy, model.optimizer])\n",
    "            tot_accuracy += accuracy\n",
    "            pbar.update(batch_size)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "print('\\nAverage training accuracy: {:.4f}'.format(tot_accuracy / iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:22<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average training accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    minibatch_size = 64\n",
    "    tot_accuracy = 0\n",
    "    for epoch in tqdm(range(10)):\n",
    "        for i, minibatch in enumerate(iterate_minibatches(X_train, y_train, minibatch_size)):\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            accuracy, _ = sess.run([model.accuracy, model.optimizer], feed_dict={data_X:minibatch_X, data_y:minibatch_Y})\n",
    "            tot_accuracy += accuracy\n",
    "\n",
    "\n",
    "print('\\nAverage training accuracy: {:.4f}'.format(tot_accuracy / iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
